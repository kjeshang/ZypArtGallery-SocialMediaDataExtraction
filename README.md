# ZypArtGallery-SocialMediaDataExtraction

## Description

This project repository contains a collection of scripts and related files that were used to extract unaggregated social media data of Zyp Art Gallery's Facebook & Instagram profiles from Facebook Graph API. The purpose of this project was to assist Zyp Art Gallery to extract social media data that was previously available to download directly as CSV files on Facebook and Instagram webpages. In the context of Facebook, the company decided to remove the feature for Facebook page creators & contributors to download unaggregated data, and replaced that feature with the _Facebook for Business_ page which provided concise yet limited data but was already aggregated, which in turn, hindered the organization to derive accurate social media insights. Deriving accurate social media insights is important as it helps Zyp Art Gallery to make optimal business decisions for the purpose of planning community endeavors, charity events, volunteer programs, and showcase art to give a voice to the voiceless. This can then help contribute to receiving donations and other forms of monetary support to help maintain the financial longevity of Zyp Art Gallery. Thus, the social media data extraction performed using the scripts in this repository greatly assisted Zyp Art Gallery to maintain access to unaggreated data, and create detailed & accurate PowerBI and Google Data Studio dashboards to help derive social media insights. For further context, the social media data extraction scripts were executed on a weekly basis.

The scripts were created using the **Python** programming language with the help of the **_Pandas_**, **_Time_**, **_Datetime_**, **_Requests_**, and **_Gspread_** packages, along with the incorporation of **Facebook Graph API**, **Google Drive API**, and **Google Sheets API**. The extracted, transformed, and cleaned data would be saved in both CSV files whereby the content is updated to combine the past data with the most curren week's data each time the Python scripts are run. This makes sure that the social media data is up-to-date. Then the contents of the CSV files is programmatically copied and pasted into pre-specified Google Sheets files on the organization's Google Drive. The other necessary requirements to utilize these scripts are the following:
* A **Facebook Account** that is added to the Zyp Art Gallery Facebook Page as a role type/contributor. The Facebook Account could be a personal one, or a new one preferably created using the organization email.
* A **Facebook for Developers** Account that is accessed using the Facebook Account and the email address associated with the respective Facebook Account.
* The **Facebook Graph API Access Token** which serves as an authentication key to make API requests to retrieve Facebook & Instagram data. Without the Access Token, one would not be able to make API requests to retrieve social media data.
* A **Google Services Account** that is created using the organization email account and the Google Cloud Console. With the Google Services Account, one will be able to access the Google Drive and Google Sheets API. The Google Services Account is also utilized in actual codebase, and it takes the form of a Gmail address.
* The **Google Services Account Private Key** which authenticates the user to take the contents of the social media data within the CSV files and paste it in the appropriate Google Sheets files so that other members of the organization can access it. Without the Private Key, one would not be able to programmatically save the social media data on the organization Google Drive.
* The **Name of the Zyp Art Gallery Facebook Page** and the **Media ID of the Zyp Art Gallery Instagram Page** are necessary to tell the API request conduction by Python code which social media page to retrieve data from.

Microsoft Visual Studio Code (VS Code) was the IDE used to construct the Python scripts. The Python version used was 3.10.1.

There are three sub-categories of Facebook & Instagram data that is retrieved from Facebook Graph API.

|Data|Explanation|
|--|--|
|Posts|Data describing the performance of the Social Media Account's posts.|
|Page|Data describing the performance of the Social Media Account's page.|
|Audience|Data describing the performance of Social Media Account in terms of Age & Gender, Country, Canadian City, and Time of Day.|

## Important Note

This GitHub repository was created for the purpose of viewing the codebase and documentation. However, the social media data files, Facebook Graph API Access Token, Google Service Account Address, and Google Services Account Private Key are not provided in this repository to protect the privacy of the Zyp Art Gallery organization and the followers of the organization's social media accounts.

## How the Project works
> This section explains in detail what was explained in the Description section. In addition, explains the flow of data in terms of extraction, transformation, and loading, which is performed by the Python scripts.

### Environment Setup
As explained in the prior section, the social media data itself was extracted using Python programming with the help of Facebook Graph API. In order to make requests to Facebook Graph API, I needed to have a Facebook account and have a page role in the organization’s Facebook page. I ended up making a Facebook account using my organization email. After creating a Facebook account, the executive director then assigned my Facebook profile to have a page role on the organization’s Facebook page. I was then able to create a ‘Facebook for Developers’ account. I then had to create an ‘app’ on Facebook for Developers, and then state the purpose of it which was simply to make requests. To gain full access to information provided by various metrics, I had to provide Zyp Art Gallery’s privacy policy for approval before gaining full access.

Even though Facebook for Developers allows for making requests within the Graph Explorer, the drawback was that some request output was too long thus pagination would occur. In other words, the entire output would not be accessible within the explorer without further manipulation. This is further exemplified by the fact that the data output is in JSON format. Thus, making the API request with the help of Python programming was easier because I could code a loop that would paginate through the JSON output. In order to make requests to Graph API via a Python script, I needed to have an access token. Although, an access token is required overall to make requests to Graph API. Within Graph Explorer, an access token is provided by default but it is only valid for approximately two hours. Thus, using a short-lived access token is not ideal when running social media data extraction code on a weekly basis. And so, I extended the access token to last approximately two months. Unfortunately, Facebook for Developers do not provide lifelong access tokens. Thus, after the current token expires, I generate a new token and extend its lifetime. An access token with a longer lifetime was more ideal for me to create the social media data extraction code. This makes the act of running the social media data extraction code easily executable on a weekly basis as I not have to keep on generating a new access token via the Graph Explorer. I only need to generate an access token with an extended lifetime every so often.

The organization utlilzes Google Drive as the primary office suite and data storage space at this current time. During the early days after I completed creating social media data extraction scripts for posts, page, & demographic insights, my final output would be a collection of data files in ‘CSV’ format. I used to manually upload them to a folder on the organization’s Google Drive. This used to be quite a tedious task. Thus, I decided to create a Google Service Account via the Google Cloud console. I then added the Google Drive and Google Sheets API. I then was able to acquire a private service account key which allows me to interact with Google Drive & Google Sheets. The next step was to create a dedicated Google Sheets file with a singular sheet that corresponds with the name of the data files in ‘CSV’ file format. The name of the Google Sheets file, sheet name, and identification value of the Google Sheets file (which is found in the URL), are utilized with the Google service account private key to take the contents of the data files in ‘CSV’ file format, and paste it into the respective Google Sheets files. The Python package called ‘gspread’ is imperative to auto-inserting the data to Google Sheets files.

### How the Project Runs
As aforementioned, the social media data extraction code was created using Python. It was coded using VS Code. There are multiple scripts that are dedicated to extracting different types of metrics, yet they all follow a similar process with slight variations in terms of data cleaning & transformation. In practice, there is another Python script that runs all of the other extraction code scripts all at once. In essence, the Python scripts I wrote go through the following stages.

